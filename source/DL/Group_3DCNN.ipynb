{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yecatstevir/teambrainiac/blob/main/source/DL/Group_3DCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssBXn9lhG9du"
      },
      "source": [
        "# Deep Learning with PyTorch\n",
        "## 3D Convolutional Neural Network on Group Brain fMRI\n",
        "Contributors: Stacey Rivet Beck, Ben Merrill\n",
        "\n",
        "- Implement 3DCNN from paper: REALLY GREAT PAPERS\n",
        "  - Nguyen et al. http://proceedings.mlr.press/v136/nguyen20a/nguyen20a.pdf\n",
        "  - Wang et al. https://arxiv.org/pdf/1801.09858.pdf (discusses more in detail the input data shapes and processing)\n",
        "  \n",
        "  - Inputs: 84@ x * y * z ; one fmri time series at a time, not concatenated\n",
        "  - Basic Architecture:\n",
        "        First layer is generating temporal descriptors of the voxels\n",
        "        Conv1 1 x 1 x 1 filter, output = 32, stride = 1, ReLU, BatchNorm\n",
        "        Conv2 7 x 7 x 7 filter, output = 64, stride = 2, ReLU, BatchNorm\n",
        "        Conv3 3 x 3 x 3 fitler, output = 64, stride = 2, ReLU, BatchNorm\n",
        "        Conv4 3 x 3 x 3 fitler, output = 128, stride = 2, ReLU, BatchNorm\n",
        "        Global Average Pooling on final feature maps ->\n",
        "        Flattened maps size 128?\n",
        "        Fully connected layer size 64\n",
        "        Fully connected layer size 2 (2 way classification, one for each class) -> softmax\n",
        "\n",
        "        Optimized with Adam, standard parameters (β1=0.9 and β2=0.999)\n",
        "        Batched at 32, but we may need to batch smaller due to GPU compute\n",
        "        Learning Rate = 0.001, gradual decay after Val loss plateaued after 15 epochs\n",
        "        Cross entropy Loss\n",
        "        Employ early stopping\n",
        "        In Wang et al. they used data for visualization, same size as input data, though are reduced in time dimension to be mapped on fsaverage surface. \n",
        "        \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjOMBc929Vpp"
      },
      "source": [
        "## Importing Dataset and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWlULVj79acH",
        "outputId": "72667fc9-7efe-4c0b-84a2-32cd51ccf09a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFAZrJHL9a6f",
        "outputId": "62292c5e-9a0a-4161-c659-9fa1cfcb625f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'teambrainiac' already exists and is not an empty directory.\n",
            "/content/teambrainiac/source/DL\n"
          ]
        }
      ],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/yecatstevir/teambrainiac.git\n",
        "\n",
        "# Change directory into cloned repo DL folder\n",
        "%cd teambrainiac/source/DL\n",
        "\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjLsWQoxMLZt"
      },
      "source": [
        "### Load path_config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "NJ5q46JZMTPc",
        "outputId": "600dc54e-d6ae-4dbd-f540-61832725ef63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2499c418-aaf4-4d38-b56d-e18f00a8c320\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2499c418-aaf4-4d38-b56d-e18f00a8c320\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving path_config.py to path_config (1).py\n",
            "User uploaded file \"path_config.py\" with length 196 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giqBoQS0MWFi"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNgdNbLKxASP",
        "outputId": "cbce859b-105d-43ed-c635-c24010da45a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.21.42)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.42 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.24.42)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.42->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.42->boto3) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.42->boto3) (1.15.0)\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.0)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.21.5)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.3.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nilearn) (4.2.6)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.7.3)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->nilearn) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.25.11)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->nilearn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Possible Missing Packages\n",
        "!pip install boto3\n",
        "!pip install nilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lAhQQqpqMYNT"
      },
      "outputs": [],
      "source": [
        "# General Library Imports\n",
        "import re\n",
        "import scipy.io\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import boto3\n",
        "import tempfile\n",
        "import tqdm\n",
        "import random\n",
        "from path_config import mat_path\n",
        "from botocore.exceptions import ClientError\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# From Local Directory\n",
        "from access_data_dl import *\n",
        "from process_dl import *\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#import torchvision.transforms as transforms\n",
        "from torch.nn import ReLU, CrossEntropyLoss, Conv3d, Module, Softmax, AdaptiveAvgPool3d\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "#from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYG_gfx5sDHc"
      },
      "source": [
        "## Import Group fMRI Data from AWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWYt1ci4sTgk",
        "outputId": "05aa424f-6bb0-4764-a6f0-b3cfabdaebbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.7 s, sys: 53.7 s, total: 1min 26s\n",
            "Wall time: 1min 30s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "path = 'dl/partition_train_4.pkl'\n",
        "train_images = access_load_data(path, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im_zt3J0qzAT",
        "outputId": "00a038eb-5574-4adf-ad50-a5c69a1b2c5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1512, 1, 79, 95, 79])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_images['images'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePdioNH3rrVT"
      },
      "source": [
        "## Build Test Batch\n",
        "Use this code only if you are changing the model based on a subset of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wRBfEmyZru0d"
      },
      "outputs": [],
      "source": [
        "# train_batch_size = 18\n",
        "\n",
        "# x = train_images['images'][:train_batch_size]\n",
        "# y = train_images['labels'][:train_batch_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqW1TnYdgyYn"
      },
      "source": [
        "## Build Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IZPwPzibTN00"
      },
      "outputs": [],
      "source": [
        "# May move this into the training bit\n",
        "# bs = 150\n",
        "\n",
        "# x_train = train_images['images']\n",
        "# y_train = train_images['labels']\n",
        "\n",
        "# ds = TensorDataset(x_train, y_train)\n",
        "# dl = DataLoader(ds, batch_size = bs, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mHyNmeLg1YG"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UDBGSQdyh3Wj"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    \n",
        "    #Conv1\n",
        "    self.conv1 = nn.Conv3d(in_channels = 1, \n",
        "                           out_channels = 32, \n",
        "                           kernel_size = (1,1,1), \n",
        "                           stride = (1,1,1)\n",
        "                           )\n",
        "    self.bn1 = nn.BatchNorm3d(32)\n",
        "    self.conv2 = nn.Conv3d(in_channels = 32, \n",
        "                           out_channels = 64, \n",
        "                           kernel_size = (7,7,7),\n",
        "                           stride = (2,2,2)\n",
        "                           )\n",
        "    self.bn2 = nn.BatchNorm3d(64)\n",
        "    self.conv3 = nn.Conv3d(in_channels = 64, \n",
        "                           out_channels = 64, \n",
        "                           kernel_size = (3,3,3),\n",
        "                           stride = (2,2,2)\n",
        "                           )\n",
        "    self.bn3 = nn.BatchNorm3d(64)\n",
        "    self.conv4 = nn.Conv3d(in_channels = 64, \n",
        "                           out_channels = 128, \n",
        "                           kernel_size = (3,3,3),\n",
        "                           stride = (2,2,2)\n",
        "                           )\n",
        "    self.bn4 = nn.BatchNorm3d(128) \n",
        "    self.pool1 = nn.AdaptiveAvgPool3d((1,1,1)) #Global Average Pool, takes the average over last two dimensions to flatten \n",
        "  \n",
        "                                                             \n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(128,64) # need to find out the size where AdaptiveAvgPool \n",
        "    self.fc2 = nn.Linear(64, 2) # left with 2 for the two classes                     \n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.bn1(F.relu(self.conv1((xb))))\n",
        "    xb = self.bn2(F.relu(self.conv2((xb)))) # Takes a long time\n",
        "    xb = self.bn3(F.relu(self.conv3((xb))))\n",
        "    xb = self.bn4(F.relu(self.conv4((xb))))\n",
        "    xb = self.pool1(xb)\n",
        "    xb = xb.view(xb.shape[:2])\n",
        "    xb = self.fc1(xb)\n",
        "    xb = self.fc2(xb)\n",
        "    return xb      \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-jsQY9v-f2fO"
      },
      "outputs": [],
      "source": [
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Get model\n",
        "model = ConvNet()\n",
        "model = model.to(device)\n",
        "# print(\"First model training on GPU\")\n",
        "# print(model)\n",
        "\n",
        "# Initialize other parameters\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "loss_func = F.cross_entropy\n",
        "opt = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YXVkGhmO8PBW"
      },
      "outputs": [],
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()\n",
        "\n",
        "\n",
        "\n",
        "# Use to load GPU model\n",
        "# model.load_state_dict(torch.load(path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kTAp6i9XReq-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_cnn(model, epochs, learning_rate, loss_func, opt, dl):\n",
        "  metrics_dict = {}\n",
        "  # Run Model\n",
        "  for epoch in range(1, 1+epochs):\n",
        "    i = 1\n",
        "    accuracy_list = []\n",
        "    loss_list = []\n",
        "    model.train()\n",
        "    print('epoch', epoch)\n",
        "    for xb, yb in dl:\n",
        "      print('batch', i)\n",
        "      i += 1\n",
        "\n",
        "      xb = xb.float()\n",
        "      pred = model(xb)\n",
        "      loss_batch = loss_func(pred, yb)\n",
        "      loss_list.append(loss_batch)\n",
        "      accuracy_batch = accuracy(pred, yb)\n",
        "      if int(accuracy_batch) == 1:\n",
        "        print('Perfect Accuracy\\nStopping early to avoid overfitting\\n\\n')\n",
        "        break\n",
        "\n",
        "\n",
        "      accuracy_list.append(accuracy_batch)\n",
        "\n",
        "      print('Batch Loss', loss_batch)\n",
        "      print('Batch Accuracy', accuracy_batch)\n",
        "\n",
        "      loss_batch.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    print('Saving model')\n",
        "    model_name = 'cnn_fmri_initial_model.pt'\n",
        "    path = F\"/content/gdrive/My Drive/{model_name}\" \n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "    metrics_dict['epoch_'+str(epoch)] = {'accuracy':accuracy_list, 'loss':loss_list}\n",
        "\n",
        "    print('epoch', epoch, 'finished\\n')\n",
        "    try:\n",
        "      past_epoch_accuracies = [sum(metrics_dict['epoch_'+str(epoch-2)]['accuracy']), sum(metrics_dict['epoch_'+str(epoch-1)]['accuracy'])]\n",
        "      current_epoch_accuracy = sum(metrics_dict['epoch_'+str(epoch)]['accuracy'])\n",
        "      if past_epoch_accuracies[0] > current_epoch_accuracy and past_epoch_accuracies[1] > current_epoch_accuracy:\n",
        "        print('Early stop to avoid overfitting\\nModel accuracies did not decrease for two epochs')\n",
        "        return model, metrics_dict\n",
        "\n",
        "    except:\n",
        "      pass\n",
        "  \n",
        "  return model, metrics_dict\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iVzucX349ZBz"
      },
      "outputs": [],
      "source": [
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Get model\n",
        "model = ConvNet()\n",
        "model = model.to(device)\n",
        "# print(\"First model training on GPU\")\n",
        "# print(model)\n",
        "\n",
        "# Initialize other parameters\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "loss_func = F.cross_entropy\n",
        "opt = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_recent_model = True\n",
        "\n",
        "if load_recent_model:\n",
        "  path = '/content/gdrive/My Drive/cnn_fmri_model_after_train_3.pt'\n",
        "  model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "zvoi-dDtIGzt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTll4mfpFWxJ",
        "outputId": "f6d56755-7b4c-4a13-9a3b-b1ac9c801190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "batch 1\n",
            "Batch Loss tensor(0.7010, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5926)\n",
            "batch 2\n",
            "Batch Loss tensor(0.7562, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5926)\n",
            "batch 3\n",
            "Batch Loss tensor(0.5570, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7407)\n",
            "batch 4\n",
            "Batch Loss tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5556)\n",
            "batch 5\n",
            "Batch Loss tensor(0.6366, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6667)\n",
            "batch 6\n",
            "Batch Loss tensor(0.5986, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5926)\n",
            "batch 7\n",
            "Batch Loss tensor(0.6287, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6667)\n",
            "batch 8\n",
            "Batch Loss tensor(0.4451, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7593)\n",
            "batch 9\n",
            "Batch Loss tensor(0.6369, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5926)\n",
            "batch 10\n",
            "Batch Loss tensor(0.4660, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8333)\n",
            "batch 11\n",
            "Batch Loss tensor(0.6030, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6852)\n",
            "batch 12\n",
            "Batch Loss tensor(0.5238, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7778)\n",
            "batch 13\n",
            "Batch Loss tensor(0.6109, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7407)\n",
            "batch 14\n",
            "Batch Loss tensor(0.5608, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7222)\n",
            "Saving model\n",
            "epoch 1 finished\n",
            "\n",
            "epoch 2\n",
            "batch 1\n",
            "Batch Loss tensor(0.4430, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7963)\n",
            "batch 2\n",
            "Batch Loss tensor(0.4687, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7222)\n",
            "batch 3\n",
            "Batch Loss tensor(0.5100, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7593)\n",
            "batch 4\n",
            "Batch Loss tensor(0.3815, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8889)\n",
            "batch 5\n",
            "Batch Loss tensor(0.3786, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 6\n",
            "Batch Loss tensor(0.3530, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 7\n",
            "Batch Loss tensor(0.3416, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 8\n",
            "Batch Loss tensor(0.3550, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 9\n",
            "Batch Loss tensor(0.2907, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9259)\n",
            "batch 10\n",
            "Batch Loss tensor(0.2958, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 11\n",
            "Batch Loss tensor(0.3097, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8889)\n",
            "batch 12\n",
            "Batch Loss tensor(0.3082, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 13\n",
            "Batch Loss tensor(0.2215, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 14\n",
            "Batch Loss tensor(0.2884, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8889)\n",
            "Saving model\n",
            "epoch 2 finished\n",
            "\n",
            "epoch 3\n",
            "batch 1\n",
            "Batch Loss tensor(0.1732, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 2\n",
            "Batch Loss tensor(0.1869, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 3\n",
            "Batch Loss tensor(0.1553, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 4\n",
            "Batch Loss tensor(0.1792, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 5\n",
            "Batch Loss tensor(0.1377, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9815)\n",
            "batch 6\n",
            "Batch Loss tensor(0.1072, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 7\n",
            "Batch Loss tensor(0.1916, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 8\n",
            "Perfect Accuracy\n",
            "Stopping early to avoid overfitting\n",
            "\n",
            "\n",
            "Saving model\n",
            "epoch 3 finished\n",
            "\n",
            "Early stop to avoid overfitting\n",
            "Model accuracies did not decrease for two epochs\n",
            "Finshed with set 0 of 504 images\n",
            "Starting next set.\n",
            "\n",
            "\n",
            "epoch 1\n",
            "batch 1\n",
            "Batch Loss tensor(0.8862, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5741)\n",
            "batch 2\n",
            "Batch Loss tensor(0.8968, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6296)\n",
            "batch 3\n",
            "Batch Loss tensor(0.7874, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6667)\n",
            "batch 4\n",
            "Batch Loss tensor(0.6273, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7593)\n",
            "batch 5\n",
            "Batch Loss tensor(0.8013, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6296)\n",
            "batch 6\n",
            "Batch Loss tensor(0.9688, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5741)\n",
            "batch 7\n",
            "Batch Loss tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5556)\n",
            "batch 8\n",
            "Batch Loss tensor(0.6450, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6852)\n",
            "batch 9\n",
            "Batch Loss tensor(0.8391, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.5185)\n",
            "batch 10\n",
            "Batch Loss tensor(0.6801, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7037)\n",
            "batch 11\n",
            "Batch Loss tensor(0.8112, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6111)\n",
            "batch 12\n",
            "Batch Loss tensor(0.5151, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7407)\n",
            "batch 13\n",
            "Batch Loss tensor(0.6234, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6667)\n",
            "batch 14\n",
            "Batch Loss tensor(0.5724, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.6667)\n",
            "Saving model\n",
            "epoch 1 finished\n",
            "\n",
            "epoch 2\n",
            "batch 1\n",
            "Batch Loss tensor(0.3314, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8889)\n",
            "batch 2\n",
            "Batch Loss tensor(0.4608, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8148)\n",
            "batch 3\n",
            "Batch Loss tensor(0.4339, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8148)\n",
            "batch 4\n",
            "Batch Loss tensor(0.3934, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8148)\n",
            "batch 5\n",
            "Batch Loss tensor(0.3350, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9259)\n",
            "batch 6\n",
            "Batch Loss tensor(0.4426, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8333)\n",
            "batch 7\n",
            "Batch Loss tensor(0.4567, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.7963)\n",
            "batch 8\n",
            "Batch Loss tensor(0.3664, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8519)\n",
            "batch 9\n",
            "Batch Loss tensor(0.3131, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8889)\n",
            "batch 10\n",
            "Batch Loss tensor(0.3881, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8889)\n",
            "batch 11\n",
            "Batch Loss tensor(0.2674, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 12\n",
            "Batch Loss tensor(0.3157, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 13\n",
            "Batch Loss tensor(0.3467, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8704)\n",
            "batch 14\n",
            "Batch Loss tensor(0.3405, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.8889)\n",
            "Saving model\n",
            "epoch 2 finished\n",
            "\n",
            "epoch 3\n",
            "batch 1\n",
            "Batch Loss tensor(0.3293, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 2\n",
            "Batch Loss tensor(0.2188, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 3\n",
            "Batch Loss tensor(0.2388, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 4\n",
            "Batch Loss tensor(0.1838, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 5\n",
            "Batch Loss tensor(0.1797, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 6\n",
            "Batch Loss tensor(0.1569, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 7\n",
            "Batch Loss tensor(0.1835, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 8\n",
            "Batch Loss tensor(0.2269, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 9\n",
            "Batch Loss tensor(0.2100, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9259)\n",
            "batch 10\n",
            "Batch Loss tensor(0.1836, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 11\n",
            "Batch Loss tensor(0.2543, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9074)\n",
            "batch 12\n",
            "Batch Loss tensor(0.1597, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9815)\n",
            "batch 13\n",
            "Batch Loss tensor(0.1350, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9630)\n",
            "batch 14\n",
            "Batch Loss tensor(0.1628, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "Saving model\n",
            "epoch 3 finished\n",
            "\n",
            "epoch 4\n",
            "batch 1\n",
            "Batch Loss tensor(0.1460, grad_fn=<NllLossBackward0>)\n",
            "Batch Accuracy tensor(0.9444)\n",
            "batch 2\n",
            "Perfect Accuracy\n",
            "Stopping early to avoid overfitting\n",
            "\n",
            "\n",
            "Saving model\n",
            "epoch 4 finished\n",
            "\n",
            "Early stop to avoid overfitting\n",
            "Model accuracies did not decrease for two epochs\n",
            "Finshed with set 1 of 504 images\n",
            "Starting next set.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "metrics_dict = {}\n",
        "for i,image_index in enumerate(range(0, train_images['images'].shape[0], 756)):\n",
        "\n",
        "  bs = 54\n",
        "\n",
        "  x_train = train_images['images'][image_index:image_index+756]\n",
        "  y_train = train_images['labels'][image_index:image_index+756]\n",
        "\n",
        "  ds = TensorDataset(x_train, y_train)\n",
        "  dl = DataLoader(ds, batch_size = bs, shuffle=True)\n",
        "\n",
        "  model, metrics = run_cnn(model, epochs, learning_rate, loss_func, opt, dl)\n",
        "  metrics_dict['round_'+str(i)] = metrics\n",
        "  \n",
        "  f = open(\"/content/gdrive/My Drive/metrics_dict_train_4%s.pkl\"%(str(i)),\"wb\")\n",
        "  pickle.dump(metrics_dict,f)\n",
        "  print('Finshed with set', str(i), 'of 504 images\\nStarting next set.\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLzXUn9re04K"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# infile = open('/content/gdrive/My Drive/metrics_dict_train_20.pkl','rb')\n",
        "# best_model2 = pickle.load(infile)"
      ],
      "metadata": {
        "id": "BR1OjThdHCNM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for x in best_model2['round_0']['epoch_6']['accuracy']:\n",
        "#   print(int(x))"
      ],
      "metadata": {
        "id": "qA1PPZWyHjL6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJGJUdiBKtnl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FyCVpQ6KtkQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKkISUtQKthJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCzbRyCiKteE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwmpLfSLKtaZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "Group_3DCNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}