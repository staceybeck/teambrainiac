{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yecatstevir/teambrainiac/blob/main/source/DL/preprocess_to_aws.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssBXn9lhG9du"
      },
      "source": [
        "# Deep Learning with PyTorch\n",
        "## 3D Convolutional Neural Network on Group Brain fMRI\n",
        "Contributors: Stacey Rivet Beck, Ben Merrill\n",
        "### To Do:\n",
        "- Either:\n",
        "  - Get Raw data in 4D   \n",
        "          - OR -\n",
        "  - Reshape Raw data into 4D from 2D\n",
        "    - Apply Whole Brain Mask to data and save to AWS\n",
        "\n",
        "- Build Dataloader: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "- Implement 3DCNN from paper: REALLY GREAT PAPERS\n",
        "  - Nguyen et al. http://proceedings.mlr.press/v136/nguyen20a/nguyen20a.pdf\n",
        "  - Wang et al. https://arxiv.org/pdf/1801.09858.pdf (discusses more in detail the input data shapes and processing)\n",
        "  \n",
        "  - Inputs: 84@ x * y * z ; one fmri time series at a time, not concatenated\n",
        "  - Basic Architecture:\n",
        "        #First layer is generating temporal descriptors of the voxels\n",
        "        Conv1 1 x 1 x 1 filter, output = 32, stride = 1, ReLU, BatchNorm\n",
        "        Conv2 7 x 7 x 7 filter, output = 64, stride = 2, ReLU, BatchNorm\n",
        "        Conv3 3 x 3 x 3 fitler, output = 64, stride = 2, ReLU, BatchNorm\n",
        "        Conv4 3 x 3 x 3 fitler, output = 128, stride = 2, ReLU, BatchNorm\n",
        "        Global Average Pooling on final feature maps ->\n",
        "        Flattened maps size 128?\n",
        "        Fully connected layer size 64\n",
        "        Fully connected layer size 2 (2 way classification, one for each class) -> softmax\n",
        "\n",
        "        Optimized with Adam, standard parameters (β1=0.9 and β2=0.999)\n",
        "        Batched at 32, but we may need to batch smaller due to GPU compute\n",
        "        Learning Rate = 0.001, gradual decay after Val loss plateaued after 15 epochs\n",
        "        Cross entropy Loss\n",
        "        Employ early stopping\n",
        "        In Wang et al. they used data for visualization, same size as input data, though are reduced in time dimension to be mapped on fsaverage surface. \n",
        "        \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjOMBc929Vpp"
      },
      "source": [
        "## Importing Dataset and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWlULVj79acH",
        "outputId": "48276d0d-18e1-4f47-8927-f3159be2fe06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFAZrJHL9a6f",
        "outputId": "cf900566-79e5-41e5-d82b-9b1c41336e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'teambrainiac'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 1152, done.\u001b[K\n",
            "remote: Counting objects: 100% (1152/1152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (900/900), done.\u001b[K\n",
            "remote: Total 1152 (delta 731), reused 474 (delta 236), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1152/1152), 83.61 MiB | 29.18 MiB/s, done.\n",
            "Resolving deltas: 100% (731/731), done.\n",
            "/content/teambrainiac/source/DL\n"
          ]
        }
      ],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/yecatstevir/teambrainiac.git\n",
        "\n",
        "# Change directory into cloned repo DL folder\n",
        "%cd teambrainiac/source/DL\n",
        "\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjLsWQoxMLZt"
      },
      "source": [
        "### Load path_config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "NJ5q46JZMTPc",
        "outputId": "f51a54c5-8689-42db-9982-5c4c40c3780b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89a9ab5a-dce6-4432-b5e0-da93ff4de7a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89a9ab5a-dce6-4432-b5e0-da93ff4de7a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving path_config.py to path_config.py\n",
            "User uploaded file \"path_config.py\" with length 196 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giqBoQS0MWFi"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNgdNbLKxASP",
        "outputId": "fe007004-f175-424a-c7cd-bb2185545f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.21.41-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 30.1 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.41\n",
            "  Downloading botocore-1.24.41-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 64.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 74.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.41->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.41->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.41 botocore-1.24.41 jmespath-1.0.0 s3transfer-0.5.2 urllib3-1.26.9\n"
          ]
        }
      ],
      "source": [
        "# Possible Missing Packages\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lAhQQqpqMYNT"
      },
      "outputs": [],
      "source": [
        "# General Library Imports\n",
        "import re\n",
        "import scipy.io\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import boto3\n",
        "import tempfile\n",
        "import tqdm\n",
        "import random\n",
        "from path_config import mat_path\n",
        "from botocore.exceptions import ClientError\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# From Local Directory\n",
        "from access_data_dl import *\n",
        "from process_dl import *\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "#import torchvision.transforms as transforms\n",
        "from torch.nn import ReLU, CrossEntropyLoss, Conv3d, Module, Softmax, AdaptiveAvgPool3d\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "#from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# from dataloader_class import DatasetFmri\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYG_gfx5sDHc"
      },
      "source": [
        "## Import Group fMRI Data, Normalize, and Create Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wWYt1ci4sTgk"
      },
      "outputs": [],
      "source": [
        "# Open path dictionary file to get subject ids\n",
        "path = \"../data/data_path_dictionary.pkl\"\n",
        "data_path_dict = open_pickle(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This is to keep hardcoded dictionary of shuffled ids to make sure train, validation, and test sets stay seperate\n",
        "\n",
        "If the size you are looking for is not here, use the function at the bottom of the cell.\n",
        "\n",
        "five_ids = {'test': ['10017_08894'],\n",
        " 'train': ['10008_09924', '10016_09694', '10004_08693'],\n",
        " 'val': ['10009_08848']}\n",
        "\n",
        "\n",
        "all_ids = {'test': ['10056_09615','10035_08847','10038_09063','30044_10095','10080_09931',\n",
        "  '30017_09567','10084_10188','10069_09785','10061_09308','10039_08941','10004_08693'],\n",
        " 'train': ['30012_09102','30027_09638','30033_09776','10033_08871',\n",
        "  '10057_10124','30036_09758','10036_09800','10047_09030','30025_09402','10043_09222','30024_09398','10066_09687',\n",
        "  '10023_09126','10050_09079','10022_08854','30053_10112','10016_09694','30011_09170','30035_09836','10065_09587',\n",
        "  '10045_08968','10008_09924','10060_09359','30014_09352','10018_08907','30020_09236','10027_09455','10046_09216',\n",
        "  '30045_10182','30038_09967','10037_09903','30009_09227','10021_08839','30004_08965','30008_08981','10053_09018'],\n",
        " 'val': ['10034_08879','10042_08990','10009_08848','10017_08894','30026_09430']}\n",
        "\n",
        "'''\n",
        "\n",
        "# generate_train_val_test_dict(subject_id_partition, train_val_test_proportion=[0.7,0.8,1])"
      ],
      "metadata": {
        "id": "0h9zKcPHxYNz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = {'test': ['10056_09615','10035_08847','10038_09063','30044_10095','10080_09931',\n",
        "  '30017_09567','10084_10188','10069_09785','10061_09308','10039_08941','10004_08693'],\n",
        " 'train': ['30012_09102','30027_09638','30033_09776','10033_08871',\n",
        "  '10057_10124','30036_09758','10036_09800','10047_09030','30025_09402','10043_09222','30024_09398','10066_09687',\n",
        "  '10023_09126','10050_09079','10022_08854','30053_10112','10016_09694','30011_09170','30035_09836','10065_09587',\n",
        "  '10045_08968','10008_09924','10060_09359','30014_09352','10018_08907','30020_09236','10027_09455','10046_09216',\n",
        "  '30045_10182','30038_09967','10037_09903','30009_09227','10021_08839','30004_08965','30008_08981','10053_09018'],\n",
        " 'val': ['10034_08879','10042_08990','10009_08848','10017_08894','30026_09430']}"
      ],
      "metadata": {
        "id": "EPkooXXlV7uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To avoid an insane amount of RAM, we will take the all_ids dictionary and split it up into chunks\n",
        "# Test and val are reasonably sized, but train is not. We will split train into 4 pieces\n",
        "train_len = len(all_ids['train'])\n",
        "all_ids['train_1'] = all_ids['train'][:int(train_len/4)]\n",
        "all_ids['train_2'] = all_ids['train'][int(train_len/4):int(train_len/2)]\n",
        "all_ids['train_3'] = all_ids['train'][int(train_len/2):int(3*train_len/4)]\n",
        "all_ids['train_4'] = all_ids['train'][int(3*train_len/4):]\n",
        "\n",
        "del all_ids['train']"
      ],
      "metadata": {
        "id": "Uahte02KyKFU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_A6VDQpeGZW",
        "outputId": "116dcd7b-0cb5-4286-8385-14244cb0f029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject ids loaded.\n",
            "Adding subjects to dictionary.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11it [02:13, 12.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Subject 1\n",
            "Completed Subject 2\n",
            "Completed Subject 3\n",
            "Completed Subject 4\n",
            "Completed Subject 5\n",
            "Completed Subject 6\n",
            "Completed Subject 7\n",
            "Completed Subject 8\n",
            "Completed Subject 9\n",
            "Completed Subject 10\n",
            "Completed Subject 11\n",
            "upload complete for dl/partition_test.pkl\n",
            "Partition test complete.\n",
            "\n",
            "Subject ids loaded.\n",
            "Adding subjects to dictionary.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:59, 11.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Subject 1\n",
            "Completed Subject 2\n",
            "Completed Subject 3\n",
            "Completed Subject 4\n",
            "Completed Subject 5\n",
            "upload complete for dl/partition_val.pkl\n",
            "Partition val complete.\n",
            "\n",
            "Subject ids loaded.\n",
            "Adding subjects to dictionary.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9it [01:48, 12.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Subject 1\n",
            "Completed Subject 2\n",
            "Completed Subject 3\n",
            "Completed Subject 4\n",
            "Completed Subject 5\n",
            "Completed Subject 6\n",
            "Completed Subject 7\n"
          ]
        }
      ],
      "source": [
        "# labels_mask_binary hyperparameters\n",
        "label_type='rt_labels'\n",
        "\n",
        "# load_subjects_by_id parameters\n",
        "n_subjects = len(data_path_dict['subject_ID'])\n",
        "runs = [2,3]\n",
        "\n",
        "# get_mask parameters and pull mask\n",
        "image_mask_type = 'mask'\n",
        "mask_ind = 0\n",
        "brain_mask = get_mask(image_mask_type, data_path_dict, mask_ind)\n",
        "\n",
        "# mask_normalize_runs_reshape_4d parameters\n",
        "scaler = 'standard'\n",
        "\n",
        "\n",
        "\n",
        "for subject_partition in all_ids.keys():\n",
        "  subject_ids = all_ids[subject_partition]\n",
        "\n",
        "  image_label_mask, image_labels = labels_mask_binary(data_path_dict, label_type='rt_labels')\n",
        "\n",
        "  initial_subject_data = load_subjects_by_id(data_path_dict, subject_ids, image_label_mask, image_labels, label_type, runs)\n",
        "\n",
        "  subjects_reshaped = mask_normalize_runs_reshape_4d(initial_subject_data, brain_mask, scaler)\n",
        "\n",
        "  partition_dictionary = train_test_aggregation_group(subjects_reshaped, runs, subject_ids)\n",
        "\n",
        "  s3_upload(partition_dictionary, 'dl/partition_%s.pkl'%subject_partition, 'pickle')\n",
        "  print('Partition', subject_partition, 'complete.')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqW1TnYdgyYn"
      },
      "source": [
        "## Build Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqf6_gSvT7Yg"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(train_dict, test_dict, bs):\n",
        "  '''\n",
        "  train_dict : Dictionary of training images and their labels\n",
        "   \n",
        "  test_dict  : Dictionary of testing images and their labels\n",
        "  '''\n",
        "\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs),#, shuffle=True),\n",
        "        DataLoader(test_ds, batch_size=bs * 2)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZPwPzibTN00"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "x_train = train_dict['images']\n",
        "y_train = train_dict['labels']\n",
        "\n",
        "x_test = test_dict['images']\n",
        "y_test = test_dict['labels']\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "test_ds = TensorDataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS3OH35RYDrZ"
      },
      "outputs": [],
      "source": [
        "bs = 6\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=bs)\n",
        "test_dl = DataLoader(test_ds, batch_size=bs*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lFZfwo7Am8t"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLxiW2kEDUrj"
      },
      "outputs": [],
      "source": [
        "# bs = 6\n",
        "\n",
        "# train_dl, test_dl = get_dataloader(train_ds, test_ds, bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPYJlsSYadkG"
      },
      "outputs": [],
      "source": [
        "# Sanity Check\n",
        "train_features, train_labels = next(iter(train_dl))\n",
        "test_features, test_labels = next(iter(test_dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGYfYVWjexRW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xerPsmwSYI-"
      },
      "source": [
        "## Practice Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "o8FdYYc8Srgg",
        "outputId": "3f2de8d3-1142-4a28-e1d9-f10158beb406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6, 32, 79, 95, 79])\n",
            "torch.Size([6, 32, 79, 95, 79])\n",
            "torch.Size([6, 64, 37, 45, 37])\n",
            "torch.Size([6, 64, 18, 22, 18])\n",
            "before drop torch.Size([6, 128, 1, 1, 1])\n",
            "after drop torch.Size([6, 128])\n",
            "after lin layer torch.Size([6, 64])\n",
            "torch.Size([6, 2])\n",
            "torch.Size([6, 32, 79, 95, 79])\n",
            "torch.Size([6, 32, 79, 95, 79])\n",
            "torch.Size([6, 64, 37, 45, 37])\n",
            "torch.Size([6, 64, 18, 22, 18])\n",
            "before drop torch.Size([6, 128, 1, 1, 1])\n",
            "after drop torch.Size([6, 128])\n",
            "after lin layer torch.Size([6, 64])\n",
            "torch.Size([6, 2])\n",
            "torch.Size([6, 32, 79, 95, 79])\n",
            "torch.Size([6, 32, 79, 95, 79])\n",
            "torch.Size([6, 64, 37, 45, 37])\n",
            "torch.Size([6, 64, 18, 22, 18])\n",
            "before drop torch.Size([6, 128, 1, 1, 1])\n",
            "after drop torch.Size([6, 128])\n",
            "after lin layer torch.Size([6, 64])\n",
            "torch.Size([6, 2])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-f116746eb423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-f116746eb423>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mHyNmeLg1YG"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDBGSQdyh3Wj"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    \n",
        "    #Conv1\n",
        "    self.conv1 = nn.Conv3d(in_channels = 1, \n",
        "                           out_channels = 32, \n",
        "                           kernel_size = (1,1,1), \n",
        "                           stride = (1,1,1)\n",
        "                           )\n",
        "    self.bn1 = nn.BatchNorm3d(32)\n",
        "    self.conv2 = nn.Conv3d(in_channels = 32, \n",
        "                           out_channels = 64, \n",
        "                           kernel_size = (7,7,7),\n",
        "                           stride = (2,2,2)\n",
        "                           )\n",
        "    self.bn2 = nn.BatchNorm3d(64)\n",
        "    self.conv3 = nn.Conv3d(in_channels = 64, \n",
        "                           out_channels = 64, \n",
        "                           kernel_size = (3,3,3),\n",
        "                           stride = (2,2,2)\n",
        "                           )\n",
        "    self.bn3 = nn.BatchNorm3d(64)\n",
        "    self.conv4 = nn.Conv3d(in_channels = 64, \n",
        "                           out_channels = 128, \n",
        "                           kernel_size = (3,3,3),\n",
        "                           stride = (2,2,2)\n",
        "                           )\n",
        "    self.bn4 = nn.BatchNorm3d(128) \n",
        "    self.pool1 = nn.AdaptiveAvgPool3d((1,1,1)) #Global Average Pool, takes the average over last two dimensions to flatten \n",
        "  \n",
        "                                                             \n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(128,64) # need to find out the size where AdaptiveAvgPool \n",
        "    self.fc2 = nn.Linear(64, 2) # left with 2 for the two classes                     \n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.bn1(F.relu(self.conv1((xb))))\n",
        "    xb = self.bn2(F.relu(self.conv2((xb)))) # Takes a long time\n",
        "    xb = self.bn3(F.relu(self.conv3((xb))))\n",
        "    xb = self.bn4(F.relu(self.conv4((xb))))\n",
        "    xb = self.pool1(xb)\n",
        "    xb = xb.view(xb.shape[:2])\n",
        "    xb = self.fc1(xb)\n",
        "    xb = self.fc2(xb)\n",
        "    return xb      \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jsQY9v-f2fO",
        "outputId": "20a2bb5f-d7d9-4a9d-842a-7157ec530989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First model training on GPU\n",
            "ConvNet(\n",
            "  (conv1): Conv3d(1, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv3d(32, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2))\n",
            "  (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
            "  (bn3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
            "  (bn4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool1): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Get model\n",
        "model = ConvNet()\n",
        "model = model.to(device)\n",
        "print(\"First model training on GPU\")\n",
        "print(model)\n",
        "\n",
        "# Initialize other parameters\n",
        "epochs = 3 #120\n",
        "learning_rate = 0.0002\n",
        "loss_func = F.cross_entropy\n",
        "opt = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "kTAp6i9XReq-",
        "outputId": "74c87678-47eb-48e0-83c3-a1f15685035d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "batch 1\n",
            "Loss tensor(0.6779, grad_fn=<NllLossBackward0>)\n",
            "batch 2\n",
            "Loss tensor(0.6765, grad_fn=<NllLossBackward0>)\n",
            "batch 3\n",
            "Loss tensor(0.6590, grad_fn=<NllLossBackward0>)\n",
            "batch 4\n",
            "Loss tensor(0.7258, grad_fn=<NllLossBackward0>)\n",
            "batch 5\n",
            "Loss tensor(0.6836, grad_fn=<NllLossBackward0>)\n",
            "batch 6\n",
            "Loss tensor(0.7156, grad_fn=<NllLossBackward0>)\n",
            "batch 7\n",
            "Loss tensor(0.7124, grad_fn=<NllLossBackward0>)\n",
            "batch 8\n",
            "Loss tensor(0.7137, grad_fn=<NllLossBackward0>)\n",
            "batch 9\n",
            "Loss tensor(0.7218, grad_fn=<NllLossBackward0>)\n",
            "batch 10\n",
            "Loss tensor(0.6575, grad_fn=<NllLossBackward0>)\n",
            "batch 11\n",
            "Loss tensor(0.7254, grad_fn=<NllLossBackward0>)\n",
            "batch 12\n",
            "Loss tensor(0.6792, grad_fn=<NllLossBackward0>)\n",
            "batch 13\n",
            "Loss tensor(0.6600, grad_fn=<NllLossBackward0>)\n",
            "batch 14\n",
            "Loss tensor(0.7117, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-9167bdc53f50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_loss' is not defined"
          ]
        }
      ],
      "source": [
        "# Run Model\n",
        "for epoch in range(1, 1+epochs):\n",
        "  model.train()\n",
        "  i = 1\n",
        "  print('epoch', epoch)\n",
        "  for xb, yb in train_dl:\n",
        "    print('batch', i)\n",
        "    i = i+1\n",
        "\n",
        "    xb = xb.float()\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    print('Loss', loss)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  print(epoch, valid_loss / len(valid_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLzXUn9re04K"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmYyDPNiRr0s"
      },
      "outputs": [],
      "source": [
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Get model\n",
        "model = ConvNet()\n",
        "model = model.to(device)\n",
        "print(\"First model training on GPU\")\n",
        "print(model)\n",
        "\n",
        "# Initialize other parameters\n",
        "epochs = 5 #120\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "\n",
        "fit(epochs, model, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB3v2KOBhYUL"
      },
      "outputs": [],
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "66UUnIhJevn9",
        "outputId": "b3a47033-0952-40ae-9e71-de9a70f52a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': [], 'val': []}\n",
            "{'train': [], 'val': []}\n",
            "\n",
            "Epoch$ : 1\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-16282038068e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m   \u001b[0mtrain_val_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-178-16282038068e>\u001b[0m in \u001b[0;36mtrain_val_model\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch$ : %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mx_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(float).to(device) # for GPU support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0my_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "  }\n",
        "\n",
        "print(accuracy_stats)\n",
        "\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "    }\n",
        "print(loss_stats)\n",
        "\n",
        "\n",
        "\n",
        "def train_test_model(epochs, model, opt, train_dl, test_dl, device):\n",
        "  for epoch in range(1, epochs+1):\n",
        "\n",
        "    # TRAINING *****************************************************************\n",
        "\n",
        "    train_epoch_loss = 0\n",
        "    train_epoch_acc = 0\n",
        "\n",
        "    # set model in training mode \n",
        "    model.train()\n",
        "    print('\\nEpoch$ : %d'%epoch)\n",
        "    for xb, yb in tqdm(train_dl):\n",
        "      xb = xb.to(device)\n",
        "      y_train_batch = y_train_batch.to(device) \n",
        "\n",
        "      #print(x_train_batch.shape)\n",
        "\n",
        "      # sets gradients to 0 to prevent interference with previous epoch\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "      # Forward pass through NN\n",
        "      y_pred = model(xb)#.to(float)\n",
        "      train_loss = criterion(y_pred, yb)\n",
        "      train_acc = accuracy(y_pred, yb)\n",
        "\n",
        "      # Backward pass, updating weights\n",
        "      train_loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      # Statistics\n",
        "      train_epoch_loss += train_loss.item()\n",
        "      train_epoch_acc += train_acc.item()\n",
        "\n",
        "\n",
        "    # VALIDATION****************************************************************   \n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "      val_epoch_loss = 0\n",
        "      val_epoch_acc = 0\n",
        "\n",
        "      model.eval()\n",
        "      for x_val_batch, y_val_batch in tqdm(validate_loader):\n",
        "      \n",
        "        x_val_batch =  x_val_batch.to(device)#.to(float)\n",
        "        y_val_batch = y_val_batch.to(device)\n",
        "            \n",
        "        # Forward pass\n",
        "        y_val_pred = model(x_val_batch)#.to(float)   \n",
        "        val_loss = criterion(y_val_pred, y_val_batch)\n",
        "        val_acc = accuracy(y_val_pred, y_val_batch)\n",
        "            \n",
        "        val_epoch_loss += val_loss.item()\n",
        "        val_epoch_acc += val_acc.item()\n",
        "\n",
        "    # Prevent plateauing validation loss \n",
        "    #scheduler.step(val_epoch_loss/len(validate_loader))\n",
        "\n",
        "        \n",
        "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "    loss_stats['val'].append(val_epoch_loss/len(validate_loader))\n",
        "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "    accuracy_stats['val'].append(val_epoch_acc/len(validate_loader))\n",
        "                              \n",
        "    \n",
        "    print(f'Epoch {epoch+0:03}: Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(validate_loader):.5f}') \n",
        "    print(f'Train Acc: {train_epoch_acc/len(train_loader):.3f} | Val Acc: {val_epoch_acc/len(validate_loader):.3f}')\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def accuracy(y_pred, y_test):\n",
        "#   # Calculating model accuracy at each epoch \n",
        "#   y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "#   _, y_pred_prob = torch.max(y_pred_softmax, dim = 1)\n",
        "#   correct_pred = (y_pred_prob == y_test).float()\n",
        "#   acc = correct_pred.sum() / len(correct_pred)\n",
        "#   acc = torch.round(acc * 100)\n",
        "\n",
        "#   return acc\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#   train_val_model(epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EBUAl0ceO4V"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()\n",
        "\n",
        "epochs = 5 #120\n",
        "learning_rate = 0.001\n",
        "loss_func = F.cross_entropy\n",
        "opt = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "\n",
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "      xb = xb.float()\n",
        "      loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "    model.eval()\n",
        "    # with torch.no_grad():\n",
        "    #     losses, nums = zip(\n",
        "    #         *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "    #     )\n",
        "    # val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "    # print(epoch, val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJGJUdiBKtnl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FyCVpQ6KtkQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKkISUtQKthJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCzbRyCiKteE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwmpLfSLKtaZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "Group_3DCNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}